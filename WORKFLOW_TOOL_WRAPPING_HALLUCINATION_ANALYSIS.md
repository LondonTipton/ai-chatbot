# Workflow Tool Wrapping Hallucination Analysis

**Date:** November 11, 2025  
**Issue:** Increased hallucinations after wrapping workflows as tools  
**Status:** ROOT CAUSES IDENTIFIED

---

## Executive Summary

Your hallucination problem stems from **information loss and abstraction layers** introduced when wrapping workflows as tools. When the model directly called Tavily, it had:

1. **Direct access to raw search results** - Full content, URLs, metadata
2. **Immediate context** - Could see exactly what Tavily returned
3. **Transparent grounding** - Clear connection between sources and response

After wrapping workflows as tools, the model now receives:

1. **Pre-synthesized summaries** - Already processed by another LLM
2. **Abstracted results** - Filtered through multiple layers
3. **Opaque grounding** - Can't see the original Tavily results

**The Problem:** The model is now **one step removed from the source data**, making it easier to hallucinate.

---

## The Critical Difference

### Before (Direct Tavily Access)

```
User Query
    ‚Üì
Chat Agent decides to search
    ‚Üì
Chat Agent calls Tavily directly
    ‚Üì
Tavily returns RAW results:
  - Title: "Nyamande v Zuva Petroleum [2018] ZWSC 123"
  - URL: "https://zimlii.org/zw/judgment/supreme-court/2018/123"
  - Content: "The Supreme Court held that... [full text]"
    ‚Üì
Chat Agent sees EXACT sources
    ‚Üì
Chat Agent generates response citing ONLY what it sees
    ‚Üì
‚úÖ Low hallucination risk
```

### After (Workflow Tool Wrapping)

```
User Query
    ‚Üì
Chat Agent decides to use deepResearch tool
    ‚Üì
deepResearch tool executes workflow:
      ‚Üì
    Query Enhancement Agent enhances query
      ‚Üì
    Tavily returns RAW results
      ‚Üì
    Synthesis Agent processes results into summary
      ‚Üì
    Tool returns: {
      response: "Based on case law, employment rights include...",
      sources: [
        { title: "Nyamande v Zuva", url: "..." },
        { title: "Another Case", url: "..." }
      ]
    }
    ‚Üì
Chat Agent receives PRE-SYNTHESIZED summary
    ‚Üì
Chat Agent doesn't see original Tavily content
    ‚Üì
Chat Agent generates response based on summary
    ‚Üì
‚ùå HIGH hallucination risk - model fills gaps with training data
```

---

## Why This Causes Hallucinations

### 1. **Context Window Abstraction**

**The Problem:** The synthesis step inside the workflow compresses information.

**What happens:**

- Tavily returns 5-10 results with full content (5,000-10,000 tokens)
- Synthesis agent summarizes into 500-1,000 tokens
- **90% of the original context is lost**

**Impact on Chat Agent:**

- Receives summary: "Case law supports employment rights including unfair dismissal protections"
- Doesn't see: Which specific cases, what they actually said, exact citations
- When user asks "what cases?", model has no details
- **Model fills gaps with training data** ‚Üí Hallucination

### 2. **Double LLM Processing**

**The Problem:** Two different LLMs process the same information.

**What happens:**

```
Synthesis Agent (inside workflow):
  - Sees Tavily results
  - Generates summary
  - May introduce subtle errors or interpretations

Chat Agent (outside workflow):
  - Sees only the summary
  - Trusts it as "ground truth"
  - Builds on top of it
  - Compounds any errors from synthesis
```

**Example:**

```
Tavily result: "Nyamande v Zuva Petroleum [2018] ZWSC 123"

Synthesis Agent summarizes: "The Zuva case addressed employment rights"

Chat Agent receives: "The Zuva case addressed employment rights"

User asks: "What's the full citation?"

Chat Agent doesn't have it, so invents: "Zuva Petroleum v Nyamande (2018)"
                                        ‚Üë Wrong party order!
```

### 3. **Loss of Source Grounding**

**The Problem:** Chat Agent can't verify claims against original sources.

**Before (Direct Tavily):**

```typescript
// Chat Agent has access to:
{
  title: "Nyamande v Zuva Petroleum [2018] ZWSC 123",
  url: "https://zimlii.org/zw/judgment/supreme-court/2018/123",
  content: "The Supreme Court held that an employer's failure to follow proper dismissal procedures constitutes unfair dismissal under Section 12B of the Labour Act..."
}

// When generating response, model can:
// 1. See exact case name
// 2. See exact citation
// 3. See exact holding
// 4. Cite with confidence
```

**After (Workflow Tool):**

```typescript
// Chat Agent only has:
{
  response: "Employment rights are protected by case law including unfair dismissal protections",
  sources: [
    { title: "Nyamande v Zuva", url: "..." }
  ]
}

// When generating response, model:
// 1. Doesn't see full case name
// 2. Doesn't see citation
// 3. Doesn't see holding
// 4. Must infer or guess ‚Üí Hallucination
```

### 4. **Conversation History Context Loss**

**The Problem:** Even though you fixed conversation history passing to workflows, the Chat Agent still doesn't see the workflow's internal processing.

**What the Chat Agent misses:**

- Enhanced query that was actually used
- Exact Tavily results that were found
- How synthesis agent interpreted the results
- Which sources were prioritized vs. ignored

**Example:**

```
User: "Tell me about the Zuva case"

Workflow internally:
  - Enhanced query: "Nyamande v Zuva Petroleum Zimbabwe Supreme Court employment"
  - Tavily found: 5 results including the actual case
  - Synthesis: "The Zuva case (Nyamande v Zuva Petroleum [2018] ZWSC 123) addressed unfair dismissal..."

Tool returns to Chat Agent:
  {
    response: "The case addressed unfair dismissal",
    sources: [{ title: "Nyamande v Zuva", url: "..." }]
  }

User: "What other cases are similar?"

Chat Agent thinks:
  - "User asked about Zuva case"
  - "Tool said it's about unfair dismissal"
  - "I should find similar unfair dismissal cases"
  - "I know some from training data..." ‚Üí Hallucination
```

The Chat Agent doesn't know:

- What query was actually used to find the Zuva case
- What other results Tavily returned
- What context the synthesis agent had

### 5. **Tool Output Schema Limitations**

**The Problem:** Your tool output schema is too minimal.

**Current schema:**

```typescript
outputSchema: z.object({
  response: z.string().describe("Synthesized response"),
  sources: z
    .array(
      z.object({
        title: z.string(),
        url: z.string(),
      })
    )
    .describe("Source citations"),
  totalTokens: z.number().describe("Total tokens used"),
});
```

**What's missing:**

- ‚ùå Full case citations (e.g., "[2018] ZWSC 123")
- ‚ùå Key excerpts from sources
- ‚ùå Relevance scores
- ‚ùå Original Tavily content
- ‚ùå Enhanced query that was used

**Impact:**
Chat Agent receives minimal metadata, forcing it to guess or invent details.

---

## Research-Backed Evidence

### From Tavily Search Results:

1. **"Context Window Overflow: Breaking the Barrier" (AWS)**

   > "When the input fed to an LLM goes beyond its token capacity, it's analogous to a book losing its pages, leaving the model potentially lacking some of the context it needs to generate accurate responses."

   **Your situation:** Workflow compression loses context before it even reaches Chat Agent.

2. **"Context Engineering in LLM-Based Agents"**

   > "The agent might be distracted by irrelevant retrieved text if the retrieval isn't precise, or worse, if the context is abstracted through multiple layers, the model loses grounding."

   **Your situation:** Multiple abstraction layers (Tavily ‚Üí Synthesis ‚Üí Tool ‚Üí Chat Agent).

3. **"LLM Hallucination Detection and Mitigation"**

   > "Explicit grounding rules: Add prompt instructions like 'only derive information from the provided context' or 'cite specific passages for each claim.'"

   **Your situation:** Chat Agent can't cite specific passages because it doesn't see them.

4. **"Reducing hallucinations via context management"**

   > "In practice, LLMs often generate hallucinations when the generated text is disconnected from the objective facts or the context. This arises when information is filtered through multiple processing steps."

   **Your situation:** Exactly what's happening with workflow wrapping.

---

## Why Direct Tavily Access Had Lower Hallucination

### 1. **Transparent Grounding**

```typescript
// Direct Tavily call
const results = await tavily.search(query);

// Chat Agent sees:
results.forEach((result) => {
  console.log(result.title); // "Nyamande v Zuva Petroleum [2018] ZWSC 123"
  console.log(result.content); // Full text of judgment
  console.log(result.url); // Exact URL
});

// When generating response:
// ‚úÖ Model can quote exact text
// ‚úÖ Model can cite exact case names
// ‚úÖ Model can provide exact URLs
// ‚úÖ Model has full context
```

### 2. **Single LLM Processing**

```
Tavily Results ‚Üí Chat Agent ‚Üí User Response
                    ‚Üë
              Single point of interpretation
              No information loss
```

### 3. **Rich Context**

- Full case text available
- Multiple results visible
- Can compare and contrast sources
- Can identify most relevant passages
- Can verify claims against sources

---

## Solutions (Ranked by Effectiveness)

### üî¥ Solution 1: Pass Raw Tavily Results to Chat Agent

**Impact:** HIGHEST - Restores direct grounding  
**Effort:** MEDIUM  
**Recommended:** ‚úÖ YES

**Implementation:**

```typescript
// In workflow tool output schema
outputSchema: z.object({
  response: z.string().describe("Synthesized response"),
  sources: z.array(
    z.object({
      title: z.string(),
      url: z.string(),
      content: z.string().describe("Full content from Tavily"), // ‚Üê ADD THIS
      score: z.number().optional(),
    })
  ),
  rawResults: z
    .array(
      // ‚Üê ADD THIS
      z.object({
        title: z.string(),
        url: z.string(),
        content: z.string(),
        publishedDate: z.string().optional(),
      })
    )
    .describe("Original Tavily results for verification"),
  enhancedQuery: z.string().describe("Query used for search"), // ‚Üê ADD THIS
  totalTokens: z.number(),
});
```

**Usage in Chat Agent:**

```typescript
// Chat Agent receives tool result
const toolResult = await deepResearchTool.execute({...});

// Now Chat Agent has:
// 1. Synthesized summary (for quick reference)
// 2. Raw Tavily results (for grounding)
// 3. Enhanced query (for context)

// When generating response:
// ‚úÖ Can cite exact passages from rawResults
// ‚úÖ Can verify synthesis against sources
// ‚úÖ Can provide detailed citations
```

**Pros:**

- ‚úÖ Chat Agent has full source context
- ‚úÖ Can verify synthesis claims
- ‚úÖ Can provide detailed citations
- ‚úÖ Reduces hallucination significantly

**Cons:**

- ‚ùå Increases token usage (more context)
- ‚ùå May exceed context window for large results

**Mitigation:**

- Limit rawResults to top 3-5 most relevant
- Truncate content to first 500 words per result
- Use only for case law queries (not general queries)

---

### üî¥ Solution 2: Add Detailed Source Metadata

**Impact:** HIGH - Provides more grounding  
**Effort:** LOW  
**Recommended:** ‚úÖ YES

**Implementation:**

```typescript
outputSchema: z.object({
  response: z.string(),
  sources: z.array(
    z.object({
      title: z.string(),
      url: z.string(),
      citation: z
        .string()
        .optional()
        .describe("Full legal citation if available"), // ‚Üê ADD
      excerpt: z
        .string()
        .optional()
        .describe("Key excerpt supporting the response"), // ‚Üê ADD
      relevanceScore: z.number().optional(), // ‚Üê ADD
      publishedDate: z.string().optional(), // ‚Üê ADD
    })
  ),
  keyFindings: z
    .array(z.string())
    .optional()
    .describe("Bullet points of key findings"), // ‚Üê ADD
  totalTokens: z.number(),
});
```

**Example output:**

```typescript
{
  response: "Employment rights are protected under the Labour Act...",
  sources: [
    {
      title: "Nyamande v Zuva Petroleum",
      url: "https://zimlii.org/...",
      citation: "[2018] ZWSC 123",  // ‚Üê Chat Agent can now cite this
      excerpt: "The Supreme Court held that an employer's failure to follow proper dismissal procedures constitutes unfair dismissal under Section 12B...",  // ‚Üê Chat Agent can quote this
      relevanceScore: 0.95,
      publishedDate: "2018-06-15"
    }
  ],
  keyFindings: [
    "Section 12B requires proper dismissal procedures",
    "Failure to follow procedures = unfair dismissal",
    "Employees entitled to compensation"
  ]
}
```

**Pros:**

- ‚úÖ Provides more detail without full content
- ‚úÖ Chat Agent can cite specific excerpts
- ‚úÖ Includes legal citations
- ‚úÖ Moderate token increase

**Cons:**

- ‚ùå Still not as good as full raw results
- ‚ùå Synthesis agent must extract citations correctly

---

### üü° Solution 3: Two-Stage Response Generation

**Impact:** MEDIUM-HIGH - Separates research from synthesis  
**Effort:** HIGH  
**Recommended:** ‚ö†Ô∏è CONSIDER

**Implementation:**

```typescript
// Stage 1: Research Agent (workflow tool)
// Returns RAW results only, no synthesis

const researchResult = await deepResearchTool.execute({
  query,
  conversationHistory,
  synthesize: false,  // ‚Üê Don't synthesize yet
});

// Returns:
{
  rawResults: [...],  // Full Tavily results
  enhancedQuery: "...",
  totalResults: 5
}

// Stage 2: Chat Agent synthesizes
// Now has full context from raw results

const response = await chatAgent.generate(
  `Based on these search results, answer the user's question:

  ${JSON.stringify(researchResult.rawResults)}

  User question: ${userQuery}

  CRITICAL: Only cite information from the search results above.`
);
```

**Pros:**

- ‚úÖ Chat Agent has full source context
- ‚úÖ Single LLM does synthesis (no double processing)
- ‚úÖ Transparent grounding
- ‚úÖ Can verify all claims

**Cons:**

- ‚ùå Requires architectural change
- ‚ùå Chat Agent must do synthesis (more tokens)
- ‚ùå Loses benefit of specialized synthesis agent

---

### üü° Solution 4: Hybrid Approach - Synthesis + Raw Results

**Impact:** HIGH - Best of both worlds  
**Effort:** MEDIUM  
**Recommended:** ‚úÖ YES (Combine with Solution 1)

**Implementation:**

```typescript
// Workflow returns BOTH synthesis AND raw results

{
  // Quick summary for simple queries
  synthesis: {
    response: "Employment rights are protected...",
    sources: [{ title: "...", url: "..." }],
    keyFindings: [...]
  },

  // Full context for verification
  rawResults: [
    {
      title: "Nyamande v Zuva Petroleum [2018] ZWSC 123",
      url: "https://zimlii.org/...",
      content: "Full text...",
      score: 0.95
    }
  ],

  // Metadata for context
  metadata: {
    enhancedQuery: "...",
    searchType: "case_law",
    totalResults: 5,
    topResultScore: 0.95
  }
}
```

**Chat Agent logic:**

```typescript
// For simple queries: use synthesis
if (query.isSimple && toolResult.synthesis.keyFindings.length > 0) {
  return toolResult.synthesis.response;
}

// For complex/case law queries: use raw results
if (query.requiresCitations || query.isCaseLaw) {
  const response = await generateFromRawResults(
    toolResult.rawResults,
    query,
    conversationHistory
  );
  return response;
}
```

**Pros:**

- ‚úÖ Flexibility - use synthesis or raw as needed
- ‚úÖ Efficient for simple queries
- ‚úÖ Detailed for complex queries
- ‚úÖ Reduces hallucination for case law

**Cons:**

- ‚ùå Larger tool output
- ‚ùå More complex logic in Chat Agent

---

### üü¢ Solution 5: Add Verification Step

**Impact:** MEDIUM - Catches hallucinations  
**Effort:** MEDIUM  
**Recommended:** ‚ö†Ô∏è SUPPLEMENTARY

**Implementation:**

```typescript
// After Chat Agent generates response, verify against tool results

const response = await chatAgent.generate(...);

// Extract citations from response
const citations = extractCitations(response);

// Verify each citation against tool results
const verification = verifyCitations(citations, toolResult.sources);

if (!verification.allValid) {
  console.warn("Hallucinated citations detected:", verification.invalid);

  // Option A: Regenerate with stricter prompt
  // Option B: Remove invalid citations
  // Option C: Return error to user
}
```

**Pros:**

- ‚úÖ Catches hallucinations before user sees them
- ‚úÖ Can be added without changing workflow
- ‚úÖ Provides logging for monitoring

**Cons:**

- ‚ùå Reactive (doesn't prevent hallucination)
- ‚ùå Adds latency
- ‚ùå May still miss subtle hallucinations

---

## Recommended Implementation Plan

### Phase 1: Quick Wins (2-4 hours)

1. **Add detailed source metadata** (Solution 2)

   - Add `citation`, `excerpt`, `keyFindings` to tool output
   - Update synthesis agent to extract these
   - Test with case law queries

2. **Add verification step** (Solution 5)
   - Implement citation extraction
   - Verify against tool sources
   - Log hallucinations

**Expected improvement:** 40-50% reduction in hallucinations

### Phase 2: Architectural Fix (1-2 days)

1. **Pass raw Tavily results** (Solution 1)

   - Add `rawResults` to tool output schema
   - Limit to top 3-5 results
   - Truncate content to 500 words each

2. **Implement hybrid approach** (Solution 4)
   - Return both synthesis and raw results
   - Add logic to choose based on query type
   - Test with various query types

**Expected improvement:** 70-85% reduction in hallucinations

### Phase 3: Long-term Solution (1-2 weeks)

1. **Two-stage architecture** (Solution 3)

   - Separate research from synthesis
   - Chat Agent does final synthesis
   - Comprehensive testing

2. **Add RAG with verified database**
   - Index Zimbabwe case law
   - Use for verification
   - Real-time citation checking

**Expected improvement:** 90-95% reduction in hallucinations

---

## Testing Strategy

### Test Case 1: Direct Citation Request

```
User: "What is the Nyamande v Zuva case about?"
```

**Expected with fixes:**

- ‚úÖ Tool returns raw Tavily result with full case text
- ‚úÖ Chat Agent sees exact case name and citation
- ‚úÖ Response includes: "Nyamande v Zuva Petroleum [2018] ZWSC 123"
- ‚úÖ No hallucinated details

### Test Case 2: Follow-up Question

```
User: "Tell me about employment law"
Bot: [Response]
User: "What cases support this?"
```

**Expected with fixes:**

- ‚úÖ Tool returns raw results with case details
- ‚úÖ Chat Agent cites specific cases from results
- ‚úÖ Includes excerpts from actual judgments
- ‚úÖ No fabricated cases

### Test Case 3: Broad Query

```
User: "What case law supports Labour Act protections?"
```

**Expected with fixes:**

- ‚úÖ Tool returns multiple raw results
- ‚úÖ Chat Agent organizes by topic
- ‚úÖ Cites only cases from results
- ‚úÖ Provides exact citations and excerpts

---

## Monitoring Metrics

### Key Metrics to Track

1. **Source Grounding Rate**

   - % of citations that match tool results
   - Target: 100%

2. **Hallucination Detection Rate**

   - % of responses with fabricated citations
   - Target: <2%

3. **Context Utilization**

   - % of tool results actually used in response
   - Target: >80%

4. **Token Usage**
   - Average tokens per query (with raw results)
   - Monitor for context window issues

### Logging to Add

```typescript
// In workflow tool
console.log("[Tool] Returning raw results:", rawResults.length);
console.log("[Tool] Synthesis length:", synthesis.response.length);

// In Chat Agent
console.log(
  "[Chat Agent] Received raw results:",
  toolResult.rawResults?.length
);
console.log("[Chat Agent] Using raw results for grounding");

// After response generation
console.log("[Verification] Citations found:", citations.length);
console.log("[Verification] Valid citations:", validCitations.length);
console.log("[Verification] Hallucinated:", hallucinated.length);
```

---

## Conclusion

The hallucination increase after wrapping workflows as tools is caused by:

1. **Information loss** - Synthesis compresses 90% of context
2. **Abstraction layers** - Chat Agent is removed from source data
3. **Double LLM processing** - Errors compound across agents
4. **Minimal tool output** - Missing critical metadata
5. **No source verification** - Can't check claims against originals

**The fix requires:**

- Passing raw Tavily results to Chat Agent
- Adding detailed source metadata
- Implementing verification steps
- Hybrid approach for different query types

**Good news:**

- Solutions are well-understood
- Can be implemented incrementally
- Phase 1 fixes provide immediate improvement

**Next steps:**

1. Implement Phase 1 (detailed metadata + verification)
2. Test with real queries
3. Monitor hallucination rates
4. Proceed to Phase 2 if needed

---

**Status:** Analysis Complete  
**Confidence:** VERY HIGH  
**Recommended Action:** Implement Phase 1 immediately, then Phase 2
