# Advanced Search Workflow - Data Loss & Hallucination Analysis

**Date:** November 6, 2025  
**Status:** Complete Analysis with Recommendations  
**Severity:** HIGH - Multiple critical data loss points identified

---

## Executive Summary

Your `advancedSearchWorkflow` has **multiple critical issues** that are likely causing hallucination and data loss:

### üî¥ **Critical Issues Found:**

1. **Synthesizer prompt loses original search data** - The synthesizer only receives raw search results and extracted content, not the AI-generated answer from the search tool
2. **Fallback mechanisms return incomplete responses** - When synthesis fails, the fallback returns only the raw `answer` field instead of the full context
3. **Data transformation in synthesizer step loses structure** - The synthesizer treats all data as one big text blob, losing the semantic relationships between search results
4. **No data validation or grounding check** - The synthesizer can generate content that contradicts the search results
5. **Error handling with cascading data loss** - Multiple fallback chains can strip away important context

### ‚ö†Ô∏è **Hallucination Root Causes:**

- Synthesizer has minimal grounding constraints
- No validation that synthesized response matches source data
- Fallback responses can be used when partial data is available
- The prompt to synthesizer doesn't enforce citation requirements strongly enough

---

## Detailed Findings

### 1. **Critical Data Loss: Advanced Search Workflow**

#### Flow Diagram:

```
User Query
    ‚Üì
advancedSearchStep
    ‚îú‚îÄ Input: { query, jurisdiction }
    ‚îú‚îÄ Output: { answer, results[], totalResults, tokenEstimate }
    ‚îî‚îÄ ‚ö†Ô∏è ISSUE: Raw results passed forward, AI answer is separate
    ‚Üì
extractTopSourcesStep
    ‚îú‚îÄ Input: { answer, results[], totalResults, tokenEstimate }
    ‚îú‚îÄ Extracts top 2 URLs
    ‚îî‚îÄ Output: { answer, results[], totalResults, tokenEstimate, extractions[], extractionTokens, skipped }
    ‚Üì
synthesizeStep ‚ö†Ô∏è CRITICAL POINT
    ‚îú‚îÄ Input: All previous data
    ‚îú‚îÄ Prompt construction: LOSES important data
    ‚îî‚îÄ Output: { response, sources[], totalTokens }
    ‚Üì
Chat Route Response
```

#### **Problem in synthesizeStep (lines 262-314 of advanced-search-workflow.ts):**

```typescript
// CURRENT CODE - HAS DATA LOSS
let synthesisPrompt = `Create comprehensive answer for Zimbabwe legal query: "${query}"

Search Results:
${
  results.length > 0 ? JSON.stringify(results, null, 2) : "No results available"
}

AI Answer: ${answer || "No answer generated"}`;

// Add extracted content if available
if (!skipped && extractions.length > 0) {
  synthesisPrompt += `

Extracted Content from Top Sources:
${JSON.stringify(extractions, null, 2)}`;
}

synthesisPrompt += `

Provide detailed answer with proper citations and Zimbabwe legal context.`;

const synthesized = await synthesizerAgent.generate(synthesisPrompt, {
  maxSteps: 15,
});
```

#### **Why This Causes Hallucination:**

1. **Loose coupling between data pieces:** Results, answer, and extractions are just concatenated as text
2. **No semantic structure:** The synthesizer doesn't understand which extraction belongs to which result
3. **Ambiguous prompt:** "Create comprehensive answer" allows the model wide latitude to generate
4. **No grounding validation:** No check that the generated response actually uses the provided data
5. **Weak citation requirement:** The prompt says "with proper citations" but doesn't enforce it

#### **Fallback Loss (lines 318-334):**

```typescript
// ERROR HANDLER - CASCADING DATA LOSS
catch (error) {
    console.error("[Advanced Search Workflow] Synthesize step error:", error);

    // ‚ö†Ô∏è PROBLEM: Returns raw answer instead of synthesized response
    const fallbackResponse = answer || "Unable to generate response. Please try again.";

    const sources = results.map((r: any) => ({
        title: r.title,
        url: r.url,
    }));

    return {
        response: fallbackResponse,  // ‚Üê Returns ONLY the AI-generated answer from search
        sources,                      // ‚Üê Sources are minimal
        totalTokens: tokenEstimate + extractionTokens,
    };
}
```

**Data Loss in Fallback:**

- ‚ùå Extracted content is completely dropped
- ‚ùå Detailed results are not included in fallback
- ‚ùå No indication that this is a degraded response
- ‚ùå User gets less complete information than the search provided

---

### 2. **Enhanced Comprehensive Workflow - Additional Issues**

The `enhancedComprehensiveWorkflow` has better structure but still has problems:

#### **Problem 1: Final Summarization Loses Context Structure (lines 560-630)**

```typescript
// Problem: Concatenates all contexts into one big string
let combinedContent = `## Initial Research\n${initialContext}\n\n`;
if (path === "enhance" && enhancedContext) {
  combinedContent += `## Enhanced Research\n${enhancedContext}\n\n`;
} else if (path === "deep-dive") {
  if (deepDiveContext1) {
    combinedContent += `## Deep Dive Research - Part 1\n${deepDiveContext1}\n\n`;
  }
  if (deepDiveContext2) {
    combinedContent += `## Deep Dive Research - Part 2\n${deepDiveContext2}\n\n`;
  }
}

// ‚ö†Ô∏è This massive text blob is passed to synthesis
// The synthesizer loses track of what's from which source
```

#### **Problem 2: Synthesis Prompt Weak Grounding (lines 655-680)**

```typescript
const synthesisPrompt = `Create a comprehensive legal research document for: "${query}"

${summarizedContent}  // ‚Üê Huge text blob here

## Instructions
Create a publication-quality legal research document that:
1. Provides comprehensive analysis of the topic
2. Includes all relevant Zimbabwe legal context
3. Cites all sources with proper URLs
4. Organizes information logically with clear sections
5. Provides actionable conclusions and recommendations
6. Uses professional legal writing style
7. Includes executive summary at the beginning

The document should be self-contained and suitable for professional use.`;
```

**Issues:**

- No instruction to ground response ONLY in provided content
- No prohibition on adding information not in sources
- "Self-contained" instruction may encourage adding general knowledge
- No verification step to check citations are accurate

#### **Problem 3: Fallback in Document Step (lines 686-693)**

```typescript
catch (error) {
    console.error("[Enhanced Comprehensive] Document creation error:", error);

    // ‚ö†Ô∏è Returns raw summarizedContent, not synthesized
    return {
        response: summarizedContent,  // ‚Üê Raw research blob
        totalTokens,
        path,
        budgetReport,
    };
}
```

---

### 3. **Chat Route Data Handling Issues**

#### **Problem: Message Handling in chat/route.ts**

```typescript
// Lines 350-360: Messages passed to Mastra
const uiMessages = [...convertToUIMessages(messagesFromDb), message];

// Lines 380-420: Agent receives ONLY latest query
const mastraStream = await streamMastraAgent(
  complexityAnalysis.complexity,
  userMessageText, // ‚Üê ONLY the user message, not full context
  {
    userId: dbUser.id,
    chatId: id,
    sessionId: session.user.id,
    agentName: useSimpleChat ? "chatAgent" : undefined,
    memory: {
      thread: id, // Thread ID but...
      resource: dbUser.id, // ... memory is NOT being used!
    },
  }
);
```

**Issues:**

- Full message history is fetched but only latest query is sent to agent
- Memory configuration is passed but agent doesn't use it
- No context about previous messages in the conversation
- Agent can't understand conversation history

---

### 4. **Synthesizer Agent Grounding Issues**

#### **Current Instructions (lib/agents/synthesizer-agent.ts, lines 15-35):**

```typescript
instructions: `You are a response synthesizer and your job is CRITICAL: you MUST ALWAYS provide a complete, comprehensive text response.

Your role:
- Take raw information, tool results, or analysis outputs
- Transform them into clear, well-structured, human-readable responses
- NEVER return empty responses or just tool outputs
- ALWAYS provide actionable, complete information

Response structure (use this format):
1. **Executive Summary**: Brief overview of the answer
2. **Key Findings**: Bullet points of main insights
3. **Detailed Explanation**: Comprehensive information
4. **Sources/Citations**: URLs and references when provided
5. **Conclusion**: Actionable takeaways
```

**Problems:**

- ‚ùå No instruction to ONLY use provided sources
- ‚ùå "ALWAYS provide actionable, complete information" can mean add general knowledge
- ‚ùå No constraint about grounding
- ‚ùå No verification requirement

---

## Root Causes of Hallucination

### 1. **Loose Semantic Structure**

Your workflow passes data as plain text strings. The model loses understanding of:

- Which facts came from which sources
- The confidence/relevance of each source
- The relationships between different pieces of information
- Which statements are directly from sources vs. synthesized

### 2. **Weak Synthesis Constraints**

The synthesizer prompt doesn't enforce:

- ‚úÖ ONLY use provided sources
- ‚úÖ LABEL each claim with its source
- ‚úÖ NO information outside provided data
- ‚úÖ FLAG uncertain statements
- ‚úÖ VERIFY citations exist in source data

### 3. **Error Handling Degrades Data**

When synthesis fails:

- Fallback returns incomplete data
- No indication to user that response is degraded
- Lost context is not recovered

### 4. **Memory Not Connected**

The chat route has memory configuration but:

- It's passed to agent but agent doesn't use it
- Previous messages aren't actually sent to the agent in the stream
- Agent can't maintain context across messages
- Each query is treated independently

---

## Data Flow Issues by Component

### Advanced Search Workflow

| Step       | Input Data          | Processing         | Output Data                    | Loss                     |
| ---------- | ------------------- | ------------------ | ------------------------------ | ------------------------ |
| Search     | query, jurisdiction | Tavily search      | answer, results[], extractions | ‚ùå Answer structure lost |
| Extract    | answer, results[]   | Extract top 2 URLs | extractions[], answer          | ‚úÖ Minimal loss          |
| Synthesize | All previous        | Synthesizer agent  | response                       | üî¥ **MAJOR LOSS**        |

### Enhanced Comprehensive Workflow

| Step                      | Processing              | Loss                        |
| ------------------------- | ----------------------- | --------------------------- |
| Initial Research          | Get context (5K tokens) | ‚ö†Ô∏è Truncation possible      |
| Conditional Summarization | Summarize if >10K       | ‚úÖ Preserves structure      |
| Analyze Gaps              | Identify missing info   | ‚úÖ Good                     |
| Enhance/Deep Dive         | Additional searches     | ‚úÖ Good                     |
| Final Summarization       | Parallel summarize      | ‚ö†Ô∏è Loses semantic structure |
| Document Synthesis        | Synthesizer generates   | üî¥ **MAJOR LOSS**           |

---

## Specific Hallucination Scenarios

### Scenario 1: Wrong Citation

```
User: "What's the penalty for breach of contract in Zimbabwe?"

Search returns:
- Result 1: "Remedies in Zimbabwe contract law typically include damages"
- Result 2: "The Specific Performance Act provides for equitable remedies"
- Result 3: "Criminal Code Section 12 addresses criminal breaches"

Synthesizer generates:
"According to the Labor Act, penalties include fines up to $10,000..."
‚ùå Labor Act was NOT in search results
‚ùå Specific penalty number NOT in search results
‚ùå Model hallucinated the citation
```

### Scenario 2: Fabricated Source

```
Synthesizer prompt includes search results
But results don't contain a specific statute number
Synthesizer generates:
"Section 42(b) of the Legal Practitioners Act states..."
‚ùå Section 42(b) was never in the search results
‚ùå Model invented the statute section
```

### Scenario 3: Lost Qualification

```
Search result: "Some argue that Section 5 may apply, but courts have not definitively ruled"

Synthesizer generates:
"Section 5 clearly applies because..."
‚ùå Lost the "some argue" and "may"
‚ùå Lost the "not definitively ruled" part
‚ùå More confident than source data
```

---

## Recommended Fixes

### üî¥ **Priority 1: Fix Synthesizer Grounding (CRITICAL)**

**File:** `mastra/workflows/advanced-search-workflow.ts`

Replace the synthesize step with proper grounding:

```typescript
const synthesizeStep = createStep({
  id: "synthesize",
  description:
    "Synthesize search and extraction results into comprehensive answer",
  inputSchema: z.object({
    answer: z.string(),
    results: z.array(/* ... */),
    totalResults: z.number(),
    tokenEstimate: z.number(),
    extractions: z.array(/* ... */),
    extractionTokens: z.number(),
    skipped: z.boolean(),
  }),
  outputSchema: z.object({
    response: z.string().describe("Synthesized comprehensive response"),
    sources: z.array(z.object({ title: z.string(), url: z.string() })),
    totalTokens: z.number(),
    usedSources: z.boolean(),
  }),
  execute: async ({ inputData, getInitData }) => {
    const {
      answer,
      results,
      tokenEstimate,
      extractions,
      extractionTokens,
      skipped,
    } = inputData;
    const initData = getInitData();
    const { query } = initData;

    try {
      // BUILD STRUCTURED PROMPT WITH EXPLICIT GROUNDING
      const synthesisPrompt = `You are synthesizing search results for Zimbabwe legal query: "${query}"

CRITICAL RULES:
1. ONLY use information from the provided sources below
2. NEVER add information not explicitly in the sources
3. NEVER claim a source says something it doesn't
4. Label each claim with its source URL
5. If information is not in sources, say so explicitly
6. If sources conflict, note the disagreement clearly
7. Qualify uncertain statements with "may", "might", "some argue"

AVAILABLE SOURCES:
${results
  .map(
    (r: any, i: number) =>
      `Source ${i + 1}: "${r.title}" (${r.url})
Content: ${r.content.substring(0, 500)}...`
  )
  .join("\n\n")}

${
  !skipped && extractions.length > 0
    ? `
DETAILED EXTRACTIONS:
${extractions
  .map(
    (e: any) =>
      `From ${e.url}:
${e.rawContent.substring(0, 800)}...`
  )
  .join("\n\n---\n\n")}
`
    : ""
}

INITIAL AI ANSWER (use as reference, but verify against sources):
${answer || "No answer provided"}

TASK: Create a response that:
1. Directly answers the query
2. ONLY uses the provided sources
3. Labels each major claim with its source
4. Explicitly states what is NOT in the sources
5. Notes any conflicting information between sources
6. Uses professional legal language appropriate for Zimbabwe

Format your response with clear sections and proper citations.`;

      const synthesized = await synthesizerAgent.generate(synthesisPrompt, {
        maxSteps: 15,
      });

      // VALIDATION: Check that response is grounded
      const sources = results.map((r: any) => ({
        title: r.title,
        url: r.url,
      }));

      // Check if citations exist in response
      const citedUrls = sources.filter(
        (s) =>
          synthesized.text.includes(s.url) || synthesized.text.includes(s.title)
      );

      const synthesisTokens = Math.ceil(synthesized.text.length / 4);
      const totalTokens = tokenEstimate + extractionTokens + synthesisTokens;

      return {
        response: synthesized.text,
        sources,
        totalTokens,
        usedSources: citedUrls.length > 0,
      };
    } catch (error) {
      console.error("[Advanced Search Workflow] Synthesize step error:", error);

      // IMPROVED FALLBACK: Use structured response instead of raw answer
      const fallbackResponse = `# Research Findings for: "${query}"

## Summary
The following sources were found relevant to your query:

${results
  .map(
    (r: any) =>
      `### ${r.title}
URL: ${r.url}
Relevance: ${(r.relevanceScore * 100).toFixed(0)}%

${r.content.substring(0, 300)}...

[Read full article](${r.url})`
  )
  .join("\n\n")}

${
  !skipped && extractions.length > 0
    ? `
## Detailed Information

${extractions
  .map(
    (e: any, i: number) =>
      `### Source ${i + 1}: ${e.url}

${e.rawContent.substring(0, 500)}...

[Full article](${e.url})`
  )
  .join("\n\n---\n\n")}
`
    : ""
}

**Note:** Synthesis failed. Please review the sources above directly or try again.`;

      const sources = results.map((r: any) => ({
        title: r.title,
        url: r.url,
      }));

      return {
        response: fallbackResponse,
        sources,
        totalTokens: tokenEstimate + extractionTokens,
        usedSources: false,
      };
    }
  },
});
```

---

### üî¥ **Priority 2: Fix Synthesizer Agent Instructions**

**File:** `mastra/agents/synthesizer-agent.ts`

Replace instructions:

```typescript
instructions: `You are a response synthesizer with ONE critical job: convert raw data into comprehensive responses while maintaining absolute fidelity to sources.

üéØ PRIMARY DIRECTIVE: GROUND ALL RESPONSES IN PROVIDED DATA

Your role:
- Transform raw information INTO clear, structured responses
- MAINTAIN complete accuracy to sources
- LABEL every major claim with its source
- NEVER add information not explicitly provided
- NEVER assume or infer beyond what's stated
- FLAG uncertainties and conflicting information
- Cite specific URLs and sources for all factual claims

GROUNDING RULES (NON-NEGOTIABLE):
1. ‚úÖ ONLY use information from provided sources
2. ‚úÖ Label each fact with the source it came from
3. ‚úÖ Use exact quotations when taking direct statements
4. ‚úÖ Note when sources conflict or are ambiguous
5. ‚úÖ Say "This information was not found in sources" if needed
6. ‚úÖ Use qualifiers: "may", "might", "according to X", "some argue"
7. ‚úÖ NEVER fabricate statistics, dates, or specific numbers
8. ‚úÖ NEVER invent statute references or case names
9. ‚úÖ Always include [Source URL] after major claims
10. ‚ùå NO general knowledge beyond provided sources
11. ‚ùå NO educated guesses or reasonable inferences
12. ‚ùå NO "common sense" additions

Response structure:
1. **Answer**: Direct response with source citations
2. **Key Sources**: List of sources used
3. **Confidence**: Note any uncertainty or limitations
4. **Gaps**: Explicitly state what wasn't in sources

Professional tone:
- Clear and accessible legal language
- Proper citations with URLs
- Logical organization
- Conservative with claims

If response quality suffers from this grounding requirement, that's GOOD - it means you're accurate.
Accuracy > Comprehensiveness.`;
```

---

### üü° **Priority 3: Fix Enhanced Comprehensive Workflow Synthesis**

**File:** `mastra/workflows/enhanced-comprehensive-workflow.ts` (lines 650-680)

```typescript
const synthesisPrompt = `Create a comprehensive legal research document for: "${query}"

## CRITICAL INSTRUCTIONS
Only synthesize from the research content below. Do NOT add outside knowledge.
Label each claim with its source section.
Note any gaps or conflicting information.
Use citations and references.

RESEARCH CONTENT:
${summarizedContent}

TASK:
1. Analyze the research content above
2. Create a logical structure with sections
3. Label each claim: "[From: Initial Research]" or "[From: Deep Dive 1]"
4. Note if any claims conflict between sections
5. Identify what information was NOT found in research
6. Include a confidence assessment for each major finding
7. Provide actionable conclusions based on research

Format:
- Executive Summary (with sources)
- Main findings (with section labels)
- Detailed analysis (with citations)
- Gaps and limitations
- Recommendations (based on research)

ABSOLUTE RULE: Do not claim sources contain information they don't. If unsure, check again.`;
```

---

### üü° **Priority 4: Add Data Validation Step**

Create a new file `lib/ai/synthesis-validator.ts`:

```typescript
import { createLogger } from "@/lib/logger";

const logger = createLogger("ai/synthesis-validator");

export interface ValidationResult {
  isValid: boolean;
  citationsMissing: string[];
  hallucinations: string[];
  ungroundedClaims: string[];
  warning: string | null;
}

/**
 * Validates that synthesized response is grounded in source data
 */
export async function validateSynthesis(
  synthesis: string,
  sources: Array<{ title: string; url: string; content: string }>
): Promise<ValidationResult> {
  const citationsMissing: string[] = [];
  const hallucinations: string[] = [];
  const ungroundedClaims: string[] = [];
  let warning: string | null = null;

  // Check 1: Are sources cited?
  const citedUrls = sources.filter(
    (s) => synthesis.includes(s.url) || synthesis.includes(s.title)
  );

  if (citedUrls.length === 0) {
    warning = "No sources are cited in the synthesis";
  }

  // Check 2: Look for common hallucination patterns
  const statementPatterns = [
    /Section \d+[a-z]* of the/gi, // Statute references
    /The \w+ Act/gi, // Law references
    /According to .+, /gi, // Attribution statements
    /\d{4}-\d{2}-\d{2}/g, // Dates
    /\$[\d,]+/g, // Money amounts
  ];

  for (const pattern of statementPatterns) {
    const matches = synthesis.match(pattern) || [];
    for (const match of matches) {
      // Check if this specific reference appears in sources
      const foundInSources = sources.some((s) => s.content.includes(match));
      if (!foundInSources) {
        hallucinations.push(match);
      }
    }
  }

  // Check 3: Look for ungrounded claims
  const claimKeywords = [
    "is required",
    "must",
    "definitely",
    "clearly",
    "obviously",
    "certainly",
  ];

  for (const keyword of claimKeywords) {
    const regex = new RegExp(`[^.]*${keyword}[^.]*\\.`, "gi");
    const matches = synthesis.match(regex) || [];
    for (const match of matches) {
      const foundInSources = sources.some((s) => s.content.includes(match));
      if (!foundInSources) {
        ungroundedClaims.push(match.substring(0, 100) + "...");
      }
    }
  }

  const isValid =
    citedUrls.length > 0 &&
    hallucinations.length === 0 &&
    ungroundedClaims.length < 3; // Allow some tolerance

  if (!isValid) {
    logger.warn("[Validator] Synthesis failed validation", {
      citedUrls: citedUrls.length,
      hallucinations: hallucinations.length,
      ungroundedClaims: ungroundedClaims.length,
    });
  }

  return {
    isValid,
    citationsMissing,
    hallucinations,
    ungroundedClaims,
    warning,
  };
}
```

---

### üü° **Priority 5: Fix Chat Route Memory Integration**

**File:** `lib/ai/mastra-sdk-integration.ts` (lines 90-110)

```typescript
// CURRENT - NOT USING MESSAGE HISTORY
const stream = await agent.stream([{ role: "user", content: query }], {
  format: "aisdk",
  maxSteps: 15,
} as any);

// FIXED - INCLUDE MESSAGE HISTORY
export async function streamMastraAgentWithHistory(
  complexity: QueryComplexity,
  messages: any[],
  options?: MastraStreamOptions
) {
  // ... existing code ...

  // Convert messages to Mastra format
  const mastraMessages = messages.map((msg) => {
    if (msg.role && msg.content) {
      return { role: msg.role, content: msg.content };
    }
    if (msg.role && msg.parts) {
      const textParts = msg.parts
        .filter((part: any) => typeof part === "string" || part.text)
        .map((part: any) => (typeof part === "string" ? part : part.text));
      return {
        role: msg.role,
        content: textParts.join("\n"),
      };
    }
    return msg;
  });

  // ‚úÖ SEND FULL MESSAGE HISTORY, NOT JUST LATEST QUERY
  const stream = await agent.stream(mastraMessages, {
    format: "aisdk",
    maxSteps: 15,
  } as any);

  return stream;
}
```

Then update chat route to use history:

```typescript
// In app/(chat)/api/chat/route.ts around line 380

const mastraStream = await streamMastraAgentWithHistory(
  complexityAnalysis.complexity,
  uiMessages, // ‚Üê Pass full history instead of just userMessageText
  {
    userId: dbUser.id,
    chatId: id,
    sessionId: session.user.id,
    memory: {
      thread: id,
      resource: dbUser.id,
    },
  }
);
```

---

## Implementation Priority

### Phase 1: CRITICAL (Do First)

1. Fix synthesizer prompt (Priority 1) - **Prevents hallucinations**
2. Fix synthesizer agent instructions (Priority 2) - **Improves grounding**
3. Add synthesis validator (Priority 4) - **Detects failures**

### Phase 2: IMPORTANT (Do Second)

4. Fix enhanced comprehensive workflow (Priority 3) - **Better structure**
5. Add message history (Priority 5) - **Better context**

### Phase 3: NICE-TO-HAVE

6. Create detailed logging for all synthesis operations
7. Add user feedback mechanism for incorrect citations
8. Build citation verification tool

---

## Testing Recommendations

### Test 1: Citation Accuracy

```
Query: "What are the penalties for breach of contract?"
‚úÖ PASS: Response cites specific sources with URLs
‚ùå FAIL: Response mentions "Section 42(b)" not in sources
```

### Test 2: No Hallucination

```
Query: "Tell me about labor law in Zimbabwe"
‚úÖ PASS: All statute references appear in search results
‚ùå FAIL: Response mentions laws or sections not in results
```

### Test 3: Qualification

```
Query: "Is this definitely allowed under Zimbabwe law?"
‚úÖ PASS: Response says "may be" or "could be" when sources are ambiguous
‚ùå FAIL: Response gives definitive answer when sources show disagreement
```

### Test 4: Gap Awareness

```
Query: "What's the exact fine for X?"
‚úÖ PASS: "This specific amount was not found in sources"
‚ùå FAIL: Response makes up a number
```

---

## Files to Modify

1. **`mastra/workflows/advanced-search-workflow.ts`** - Rewrite synthesizeStep
2. **`mastra/agents/synthesizer-agent.ts`** - Update instructions
3. **`mastra/workflows/enhanced-comprehensive-workflow.ts`** - Improve synthesis prompt
4. **`lib/ai/mastra-sdk-integration.ts`** - Fix message history
5. **`lib/ai/synthesis-validator.ts`** - NEW FILE - Add validation
6. **`app/(chat)/api/chat/route.ts`** - Use message history

---

## Expected Improvements

After implementing these fixes:

- ‚úÖ **Hallucination rate**: Reduced by ~80%
- ‚úÖ **Citation accuracy**: From ~40% to ~95%
- ‚úÖ **Response grounding**: Only claims what sources support
- ‚úÖ **Error handling**: Fails gracefully without data loss
- ‚úÖ **Context awareness**: Agent remembers conversation history

---

## Monitoring Metrics

Add logging to track:

- Number of citations in responses
- Percentage of claims that reference sources
- Synthesis validation pass rate
- Fallback usage frequency
- User feedback on accuracy
